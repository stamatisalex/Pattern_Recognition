# -*- coding: utf-8 -*-
"""prelab_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13AewqXiq0yfly58gF9fddmKMcIK0iRZV
"""

import numpy as np
import os
import random
import gzip
import librosa.display
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
from torch.nn.utils.rnn import pack_padded_sequence
from torch.nn.utils.rnn import pad_packed_sequence
from sklearn.metrics import classification_report

"""**Βήμα 0**"""

os.listdir("../input/patreco3-multitask-affective-music/data/")

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the "../input/" directory.
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

"""**Βήμα 1**

α)
"""

with open('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/train_labels.txt', 'r') as f:
        lines = f.readlines()
        
        index1=random.randint(0,len(lines)-1)
        line1=lines[index1]
        spec_file1=line1.split()[0]
        label1=line1.split()[1]

        index2=random.randint(0,len(lines)-1)
        line2=lines[index2]
        spec_file2=line2.split()[0]
        label2=line2.split()[1]
        while label2==label1:
            index2=random.randint(0,len(lines)-1)
            line2=lines[index2]
            spec_file2=line2.split()[0]
            label2=line2.split()[1]
            
        line2=lines[index2]
        print('Labels chosen:', label1, label2)
        print('Spec files chosen:', spec_file1, spec_file2)

"""β)"""

spectrogram_file_1 = '../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/train/'+spec_file1[:-3]
spectrogram_file_2 = '../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/train/'+spec_file2[:-3]

spectrograms_1 = np.load(spectrogram_file_1)
spectrograms_2 = np.load(spectrogram_file_2)


# spectrograms contains a fused mel spectrogram and chromagram
# Decompose as follows
mel_spectrogram_1 = spectrograms_1[:128]
chromagram_1 = spectrograms_1[128:]
mel_spectrogram_2 = spectrograms_2[:128]
chromagram_2 = spectrograms_2[128:]

print(mel_spectrogram_1.shape)
print(chromagram_1.shape)
print(mel_spectrogram_2.shape)
print(chromagram_2.shape)

"""γ)"""

fig, (ax1,ax2) = plt.subplots(1,2,figsize=(22,8))
img = librosa.display.specshow(mel_spectrogram_1, x_axis='time', y_axis='linear', ax=ax1)
ax1.set(title=spec_file1+": "+label1)
fig.colorbar(img, ax=ax1, format="%+2.f dB")
img = librosa.display.specshow(mel_spectrogram_2, x_axis='time', y_axis='linear', ax=ax2)
ax2.set(title=spec_file2+": "+label2)
fig.colorbar(img, ax=ax2, format="%+2.f dB")

"""**Βήμα 2**

α)
"""

print('Shape of spectrogram for '+label1+':',mel_spectrogram_1.shape)
print('Shape of spectrogram for '+label2+':',mel_spectrogram_2.shape)

"""β)"""

spectrogram_file_1 = '../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/train/'+spec_file1[:-3]
spectrogram_file_2 = '../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/train/'+spec_file2[:-3]

spectrograms_1_beat = np.load(spectrogram_file_1)
spectrograms_2_beat = np.load(spectrogram_file_2)


# spectrograms contains a fused mel spectrogram and chromagram
# Decompose as follows
mel_spectrogram_1_beat = spectrograms_1_beat[:128]
chromagram_1_beat = spectrograms_1_beat[128:]
mel_spectrogram_2_beat = spectrograms_2_beat[:128]
chromagram_2_beat = spectrograms_2_beat[128:]

print(mel_spectrogram_1_beat.shape)
print(chromagram_1_beat.shape)
print(mel_spectrogram_2_beat.shape)
print(chromagram_2_beat.shape)

print('Shape of beat-synced spectrogram for '+label1+':',mel_spectrogram_1_beat.shape)
print('Shape of beat-synced spectrogram for '+label2+':',mel_spectrogram_2_beat.shape)

fig, (ax1,ax2) = plt.subplots(1,2,figsize=(22,8))
img = librosa.display.specshow(mel_spectrogram_1_beat, x_axis='time', y_axis='linear', ax=ax1)
ax1.set(title=spec_file1+": "+label1)
fig.colorbar(img, ax=ax1, format="%+2.f dB")
img = librosa.display.specshow(mel_spectrogram_2_beat, x_axis='time', y_axis='linear', ax=ax2)
ax2.set(title=spec_file2+": "+label2)
fig.colorbar(img, ax=ax2, format="%+2.f dB")

"""**Βήμα 3**"""

fig, (ax1,ax2) = plt.subplots(1,2,figsize=(22,8))
img = librosa.display.specshow(chromagram_1, x_axis='time', y_axis='linear', ax=ax1)
ax1.set(title=spec_file1+": "+label1)
fig.colorbar(img, ax=ax1, format="%+2.f dB")
img = librosa.display.specshow(chromagram_2, x_axis='time', y_axis='linear', ax=ax2)
ax2.set(title=spec_file2+": "+label2)
fig.colorbar(img, ax=ax2, format="%+2.f dB")

print('Shape of chromagram for '+label1+':',chromagram_1.shape)
print('Shape of chromagram for '+label2+':',chromagram_2.shape)

fig, (ax1,ax2) = plt.subplots(1,2,figsize=(22,8))
img = librosa.display.specshow(chromagram_1_beat, x_axis='time', y_axis='linear', ax=ax1)
ax1.set(title=spec_file1+": "+label1)
fig.colorbar(img, ax=ax1, format="%+2.f dB")
img = librosa.display.specshow(chromagram_2_beat, x_axis='time', y_axis='linear', ax=ax2)
ax2.set(title=spec_file2+": "+label2)
fig.colorbar(img, ax=ax2, format="%+2.f dB")

print('Shape of beat-synced chromagram for '+label1+':',chromagram_1_beat.shape)
print('Shape of beat-synced chromagram for '+label2+':',chromagram_2_beat.shape)

"""**Βήμα 4**

γ)
"""

# this cell contains code provided by lab file: dataset.py, with two added functions

import copy
from sklearn.preprocessing import LabelEncoder
from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler

# HINT: Use this class mapping to merge similar classes and ignore classes that do not work very well
CLASS_MAPPING = {
    "Rock": "Rock",
    "Psych-Rock": "Rock",
    "Indie-Rock": None,
    "Post-Rock": "Rock",
    "Psych-Folk": "Folk",
    "Folk": "Folk",
    "Metal": "Metal",
    "Punk": "Metal",
    "Post-Punk": None,
    "Trip-Hop": "Trip-Hop",
    "Pop": "Pop",
    "Electronic": "Electronic",
    "Hip-Hop": "Hip-Hop",
    "Classical": "Classical",
    "Blues": "Blues",
    "Chiptune": "Electronic",
    "Jazz": "Jazz",
    "Soundtrack": None,
    "International": None,
    "Old-Time": None,
}


def torch_train_val_split(
    dataset, batch_train, batch_eval, val_size=0.2, shuffle=True, seed=420
):
    # Creating data indices for training and validation splits:
    dataset_size = len(dataset)
    indices = list(range(dataset_size))
    val_split = int(np.floor(val_size * dataset_size))
    if shuffle:
        np.random.seed(seed)
        np.random.shuffle(indices)
    train_indices = indices[val_split:]
    val_indices = indices[:val_split]

    # Creating PT data samplers and loaders:
    train_sampler = SubsetRandomSampler(train_indices)
    val_sampler = SubsetRandomSampler(val_indices)

    train_loader = DataLoader(dataset, batch_size=batch_train, sampler=train_sampler)
    val_loader = DataLoader(dataset, batch_size=batch_eval, sampler=val_sampler)
    return train_loader, val_loader


def read_spectrogram(spectrogram_file, chroma=True):
    # with open(spectrogram_file, "r") as f:
    spectrograms = np.load(spectrogram_file)
    # spectrograms contains a fused mel spectrogram and chromagram
    # Decompose as follows
    return spectrograms.T

# __________________________________additions_______________________________________

def read_mel_spectrogram(spectrogram_file, chroma=True):
    # with open(spectrogram_file, "r") as f:
    spectrograms = np.load(spectrogram_file)[:128]
    # spectrograms contains a fused mel spectrogram and chromagram
    # Decompose as follows
    return spectrograms.T

def read_chromagram(spectrogram_file, chroma=True):
    # with open(spectrogram_file, "r") as f:
    spectrograms = np.load(spectrogram_file)[128:]
    # spectrograms contains a fused mel spectrogram and chromagram
    # Decompose as follows
    return spectrograms.T
#___________________________________________________________________________________

class LabelTransformer(LabelEncoder):
    def inverse(self, y):
        try:
            return super(LabelTransformer, self).inverse_transform(y)
        except:
            return super(LabelTransformer, self).inverse_transform([y])

    def transform(self, y):
        try:
            return super(LabelTransformer, self).transform(y)
        except:
            return super(LabelTransformer, self).transform([y])


class PaddingTransform(object):
    def __init__(self, max_length, padding_value=0):
        self.max_length = max_length
        self.padding_value = padding_value

    def __call__(self, s):
        if len(s) == self.max_length:
            return s

        if len(s) > self.max_length:
            return s[: self.max_length]

        if len(s) < self.max_length:
            s1 = copy.deepcopy(s)
            pad = np.zeros((self.max_length - s.shape[0], s.shape[1]), dtype=np.float32)
            s1 = np.vstack((s1, pad))
            return s1


class SpectrogramDataset(Dataset):
    def __init__(
        self, path, class_mapping=None, train=True, max_length=-1, regression=None, spect_type='spectrogram'
    ):
        t = "train" if train else "test"
        p = os.path.join(path, t)
        self.regression = regression
        self.index = os.path.join(path, "{}_labels.txt".format(t))
        self.files, labels = self.get_files_labels(self.index, class_mapping)

        if spect_type=='spectrogram':
            self.feats = [read_spectrogram(os.path.join(p, f)) for f in self.files]
        elif spect_type=='mel_spectrogram':
            self.feats = [read_mel_spectrogram(os.path.join(p, f)) for f in self.files]
        else:
            self.feats = [read_chromagram(os.path.join(p, f)) for f in self.files]
            
        self.feat_dim = self.feats[0].shape[1]
        self.lengths = [len(i) for i in self.feats]
        self.max_length = max(self.lengths) if max_length <= 0 else max_length
        self.zero_pad_and_stack = PaddingTransform(self.max_length)
        self.label_transformer = LabelTransformer()
        if isinstance(labels, (list, tuple)):
            if not regression:
                self.labels = np.array(
                    self.label_transformer.fit_transform(labels)
                ).astype("int64")
            else:
                self.labels = np.array(labels).astype("float64")

    def get_files_labels(self, txt, class_mapping):
        with open(txt, "r") as fd:
            lines = [l.rstrip().split("\t") for l in fd.readlines()[1:]]
        files, labels = [], []
        for l in lines:
            if self.regression:
                l = l[0].split(",")
                files.append(l[0] + ".fused.full.npy")
                labels.append(l[self.regression])
                continue
            label = l[1]
            if class_mapping:
                label = class_mapping[l[1]]
            if not label:
                continue
            fname = l[0]
            if fname.endswith(".gz"):
                fname = ".".join(fname.split(".")[:-1])
            #if not train:
            #    temp = l[0].split(".")
            #    fname=temp[0] + ".fused.full.npy"
            
            temp = l[0].split(".")
            fname=temp[0] + ".fused.full.npy"
            
            files.append(fname)
            labels.append(label)
        return files, labels

    def __getitem__(self, item):
        length = min(self.lengths[item], self.max_length)
        return self.zero_pad_and_stack(self.feats[item]), self.labels[item], length

    def __len__(self):
        return len(self.labels)

# this cell contains code provided by lab file: dataset.py

dataset = SpectrogramDataset(
        '../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/', class_mapping=CLASS_MAPPING, train=True
    )

print(dataset[10])
print(f"Input: {dataset[10][0].shape}")
print(f"Label: {dataset[10][1]}")
print(f"Original length: {dataset[10][2]}")

# create dataset instances with and without mapping:
dataset_before_mapping=SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/', train=True)
dataset_after_mapping=SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/', class_mapping=CLASS_MAPPING, train=True)

# find all labels in each mapping:

labels_before_mapping=[]
for item in dataset_before_mapping:
    labels_before_mapping.append(item[1])

labels_after_mapping=[]
for item in dataset_after_mapping:
    labels_after_mapping.append(item[1])

print(len(set(labels_after_mapping)))

# create histograms:

f, (ax1,ax2) = plt.subplots(1,2,figsize=(18,6))
plt.title('Histograms of labels', fontsize=22, pad=40)

ax1.set_title('Histogram before class mapping', fontsize=18)
ax1.hist(labels_before_mapping, bins=len(set(labels_before_mapping)))

ax2.set_title('Histogram after class mapping', fontsize=18)
ax2.hist(labels_after_mapping, bins=len(set(labels_after_mapping)))

"""**Βήμα 5**"""

# setting device on GPU if available, else CPU
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print('Using device:', device)

class BasicLSTM(nn.Module):
    def __init__(self, input_dim, rnn_size, output_dim, num_layers, bidirectional=False, dropout=0):
        super(BasicLSTM, self).__init__()
        self.bidirectional = bidirectional
        self.feature_size = rnn_size * 2 if self.bidirectional else rnn_size
        self.num_layers = num_layers
        self.hidden_size=rnn_size
        self.dropout=dropout

        # --------------- Insert your code here ---------------- #
        # Initialize the LSTM, Dropout, Output layers

        self.lstm = nn.LSTM(input_size=input_dim, hidden_size=rnn_size, num_layers=num_layers, batch_first=True, bidirectional=self.bidirectional, dropout=self.dropout) #lstm
        self.linear = nn.Linear(self.feature_size, output_dim)

    def forward(self, x, lengths):
        """ 
            x : 3D numpy array of dimension N x L x D
                N: batch index
                L: sequence index
                D: feature index

            lengths: N x 1
         """
        
        # --------------- Insert your code here ---------------- #
        
        # You must have all of the outputs of the LSTM, but you need only the last one (that does not exceed the sequence length)
        # To get it use the last_timestep method
        # Then pass it through the remaining network
        
        if not self.bidirectional:
            factor=1
        else:
            factor=2
            
#         h_0 = torch.zeros(self.num_layers*factor, x.size(0), self.hidden_size) #hidden state
#         c_0 = torch.zeros(self.num_layers*factor, x.size(0), self.hidden_size) #internal state
        
        x_packed = pack_padded_sequence(x.cpu(), lengths.cpu(), batch_first = True, enforce_sorted = False).to(device) 
        output, (hn, cn) = self.lstm(x_packed)  #lstm with input, hidden, and internal state
        output_unpacked,_ = pad_packed_sequence(output,batch_first = True)
        
        last_timestep_output=self.last_timestep(output_unpacked, lengths, self.bidirectional)
        last_outputs = self.linear(last_timestep_output)
        
        return last_outputs

    def last_timestep(self, outputs, lengths, bidirectional=False):
        """
            Returns the last output of the LSTM taking into account the zero padding
        """
        if bidirectional:
            forward, backward = self.split_directions(outputs)
            last_forward = self.last_by_index(forward, lengths)
            last_backward = backward[:, 0, :]
            # Concatenate and return - maybe add more functionalities like average
            return torch.cat((last_forward, last_backward), dim=-1)

        else:
            return self.last_by_index(outputs, lengths)

    @staticmethod
    def split_directions(outputs):
        direction_size = int(outputs.size(-1) / 2)
        forward = outputs[:, :, :direction_size]
        backward = outputs[:, :, direction_size:]
        return forward, backward

    @staticmethod
    def last_by_index(outputs, lengths):
        # Index of the last output for each sequence.
        idx = (lengths - 1).view(-1, 1).expand(outputs.size(0),
                                               outputs.size(2)).unsqueeze(1)
        return outputs.gather(1, idx).squeeze()

"""###3: Train LSTM, print only training loss per epoch"""

def train_model(model,optimizer,criterion,num_epochs,train_loader,validation_loader=None,validate=False,device="cuda", overfit_batch=False,patience=4,early_stopping=True):
  
  # _____train model:_____
    
    model.to(device)
    train_losses=[]                                          # array to hold mean train losses per epoch
    validation_losses=[]
    
    last_loss = 1000                                         # variable to hold loss of previous epoch, initialize to abig number
    trigger_times = 0                                        # number of times loss has not decreased
    epochs_performed=0
    
    if overfit_batch:                                        # if we want o overfit with training in one batch
        overfit_train_batch=next(iter(train_loader))         # get one batch from train loader
    
    for j in range(num_epochs):
        epochs_performed+=1                                  # increase number of epochs for which we have trained the model 
        train_loss_batch = []                                # array to hold train losses per batch

        if not overfit_batch:                                # normal training
            for i, data in enumerate(train_loader,0):        # for all batches
                if device:                                   # if we have GPU available
                    X=data[0].float().cuda()
                    y=data[1].cuda()
                    length=data[2].cuda()
                else:                                        # we are running on CPU
                    print('CPU')           
                    X=data[0].float()
                    y=data[1]
                    lenght=data[2]

                optimizer.zero_grad()                         # set gradients to zero

                outputs = model(X,length)                     # give input to model and get output                    

                loss = criterion(outputs, y)                  # calculate loss 

                loss.backward()                               # compute gradient   
                optimizer.step()                              # update parameters
                train_loss_batch.append(loss.item())          # add batch loss to array 
        else:                                                 # we are overfitting by training in only one batch
            data=overfit_train_batch                          # our data is the one batch
            if device:
                X=data[0].float().cuda()
                y=data[1].cuda()
                length=data[2].cuda()
            else:
                print('CPU')
                X=data[0].float()
                y=data[1]
                lenght=data[2]

            optimizer.zero_grad()                          # set gradients to zero

            outputs = model(X,length)                      # give input to model and get output                    

            loss = criterion(outputs, y)                   # calculate loss 

            loss.backward()                                # compute gradient   
            optimizer.step()                               # update parameters
            train_loss_batch.append(loss.item())           # add batch loss to array
            

        mean_training_loss=np.mean(train_loss_batch)           # calculate average training loss for epoch 
        train_losses.append(mean_training_loss)

        # _____evaluate on validation set:_____

        if validate and not overfit_batch:                     # in the case of overfitting with one batch we do not perform validation
            validation_loss_batch=[]                           # array to hold validation losses per batch
            with torch.no_grad():                              # disable gradient calculation as we will not call torch.backward()
                model.eval()

                for i, val_data in enumerate(validation_loader,0):
                    if device:
                        X_val=val_data[0].float().cuda()
                        y_val=val_data[1].cuda()
                        length_val=val_data[2].cuda()
                    else:
                        X_val=val_data[0].float()
                        y_val=val_data[1]
                        lenght_val=val_data[2]

                    pred = model(X_val,length_val)                 # get predictions
                    loss = criterion(pred,y_val)                   # calculate loss 
                    validation_loss_batch.append(loss.item())      # add batch loss to array

            model.train()                                          # train mode reset
            mean_validation_loss=np.mean(validation_loss_batch)    # calculate mean loss in epoch
            validation_losses.append(mean_validation_loss)
  
        print("Epoch {}: Mean training loss per epoch: {}".format(j,mean_training_loss))
        if validate and not overfit_batch:
            print("Epoch {}: Mean validation loss per epoch: {}".format(j,mean_validation_loss))
        print('--------------------------------------------------------------------------')
    
    
         # _____early stopping:_____ 
        
        if early_stopping and not overfit_batch:
            if mean_validation_loss >= last_loss:

                trigger_times += 1
                print('Number of times validation loss has not decreased:', trigger_times)
                print('--------------------------------------------------------------------------')

                if trigger_times >= patience:
                    print('Early stopping...')
                    if validate:
                        return model,train_losses, validation_losses, j+1
                    else:
                        return train_losses, j+1

            else:
                trigger_times = 0           
                torch.save(model.state_dict(), './model.pt')   # create checkpoint

            last_loss = mean_validation_loss
    
    
    if validate:
        return model,train_losses, validation_losses, j+1
    else:
        return train_losses, j+1

def evaluate(model, test_dataset, batch_size, device="cuda"):      # function to evaluate a trained model on a test set
   
    test_loader = DataLoader(test_dataset, batch_size=batch_size)  # create dataloader from data
    model.eval()                                                   # we are performing evaluation
    
    y_pred=[]                                                      # array to hold our predictions
    y_real=[]                                                      # array to hold real labels
    
    for i, test_data in enumerate(test_loader,0):                  # for all batches
        if device:                                                 # we are using GPU
            X=test_data[0].float().cuda()
            y=test_data[1].cuda()
            length=test_data[2].cuda()
        else:                                                      # we are using CPU
            print('CPU')
            X=test_data[0].float()
            y=test_data[1]
            lenght=test_data[2]
        
        pred = model(X, length)                                    # get model predictions for batch
        y_predict=torch.argmax(pred,dim=1)                         # get maximum for each sample: the predicted class
        
        if device:                                                 # covert to lists, depending on GPU or CPU 
            y_predict= y_predict.data.cpu().numpy().tolist()
            y=y.data.cpu().numpy().tolist()
        else:
            y_predict=y_predict.data.numpy().tolist()
            y=y.data.numpy().tolist()
        
        y_pred+=y_predict                                          # add predictions to predictions from previuos batches
        y_real += y                                                # add labels to labels from previous batches
        
    print(classification_report(y_real, y_pred))                   # print evaluation metrics
    
    return

"""β)"""

#dataset split
batch_size = 32
val_size = 0.15
mels = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/',class_mapping=CLASS_MAPPING,train=True,spect_type='mel_spectrogram')
train_loader_mel, validation_loader_mel = torch_train_val_split(mels, batch_size ,batch_size, val_size)

#model parameters
rnn_dim = 64
input_dim = 128  # length of mel spectogram
output_dim = 10  # number of classes
num_layers = 2
num_epochs = 900
learning_rate = 1e-4
bidirectional = True 
dropout = 0.2
weight_decay = 1e-4
early_stopping = True

model = BasicLSTM(input_dim, rnn_dim, output_dim, num_layers, dropout=dropout)                      # initialize model
# model.to(device)
criterion = nn.CrossEntropyLoss()                                                                   # loss function
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)       # optimizer with L2 normalizaton

model, train_losses, validation_losses, epochs_run=train_model(model,optimizer,criterion,num_epochs,train_loader=train_loader_mel,validation_loader=validation_loader_mel,validate=True, early_stopping=early_stopping, patience=3, overfit_batch=True)

x=np.arange(epochs_run)
plt.plot(x,train_losses,label='Training loss')
plt.title('Training loss per epoch for beat-synced mel spectrogram witn overfiting with one batch',fontsize=12)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# testing
test_dataset = SpectrogramDataset('/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/', class_mapping=CLASS_MAPPING,train=False,spect_type='mel_spectrogram')
batch_train = 32
evaluate(model, test_dataset ,batch_train)

"""γ)

**Απλά mel-spectrograms:**
"""

#dataset split
batch_size = 32
val_size = 0.15
mels = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/',class_mapping=CLASS_MAPPING,train=True,spect_type='mel_spectrogram')
train_loader, validation_loader = torch_train_val_split(mels, batch_size ,batch_size, val_size)

#model parameters
rnn_dim = 64
input_dim = 128  # length of mel spectogram
output_dim = 10  # number of classes
num_layers = 2
num_epochs = 60
learning_rate = 1e-4
bidirectional = True 
dropout = 0.4
weight_decay = 1e-4
early_stopping = True

model = BasicLSTM(input_dim, rnn_dim, output_dim, num_layers, dropout=dropout)                      # initialize model
criterion = nn.CrossEntropyLoss()                                                                   # loss function
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)       # optimizer with L2 normalizaton

model, train_losses, validation_losses, epochs_run=train_model(model,optimizer,criterion,num_epochs,train_loader=train_loader,validation_loader=validation_loader,validate=True, early_stopping=early_stopping, patience=3)

x=np.arange(epochs_run)
plt.plot(x,train_losses,label='Training loss')
plt.plot(x,validation_losses,label='Validation loss')
plt.title('Training and validation loss per epoch for mel spectrogram',fontsize=12)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# testing
test_dataset = SpectrogramDataset('/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/', class_mapping=CLASS_MAPPING,train=False,spect_type='mel_spectrogram')
batch_train = 32
evaluate(model, test_dataset ,batch_train)

"""δ)

**Beat-synced mel-spectrograms**
"""

#dataset split
batch_size = 32
val_size = 0.15
mels = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/',class_mapping=CLASS_MAPPING,train=True,spect_type='mel_spectrogram')
train_loader, validation_loader = torch_train_val_split(mels, batch_size ,batch_size, val_size)

model = BasicLSTM(input_dim, rnn_dim, output_dim, num_layers, dropout=dropout)                      # initialize model
# model.to(device)
criterion = nn.CrossEntropyLoss()                                                                   # loss function
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)       # optimizer with L2 normalizaton

#model parameters
rnn_dim = 64
input_dim = 128  # length of mel spectogram
output_dim = 10  # number of classes
num_layers = 2
num_epochs = 60
learning_rate = 1e-4
bidirectional = True 
dropout = 0.4
weight_decay = 1e-4
early_stopping = True

model, train_losses, validation_losses, epochs_run=train_model(model,optimizer,criterion,num_epochs,train_loader=train_loader,validation_loader=validation_loader,validate=True, early_stopping=early_stopping, patience=3)

x=np.arange(epochs_run)
plt.plot(x,train_losses,label='Training loss')
plt.plot(x,validation_losses,label='Validation loss')
plt.title('Training and validation loss per epoch for beat-synced mel spectrogram',fontsize=12)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# testing
test_dataset = SpectrogramDataset('/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/', class_mapping=CLASS_MAPPING,train=False,spect_type='mel_spectrogram')
batch_train = 32
evaluate(model, test_dataset ,batch_train)

"""ε)

**Απλά chromagrams:**
"""

#dataset split
batch_size = 32
val_size = 0.15
chromas = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/',class_mapping=CLASS_MAPPING,train=True,spect_type='chromagram')
train_loader, validation_loader= torch_train_val_split(chromas, batch_size ,batch_size, val_size)

#model parameters
rnn_dim = 64
input_dim = 12  # length of mel spectogram
output_dim = 10  # number of classes
num_layers = 2
num_epochs = 60
learning_rate = 1e-4
bidirectional = True 
dropout = 0.4
weight_decay = 1e-4
early_stopping = True

model = BasicLSTM(input_dim, rnn_dim, output_dim, num_layers, dropout=dropout)                      # initialize model
# model.to(device)
criterion = nn.CrossEntropyLoss()                                                                   # loss function
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)       # optimizer with L2 normalizaton

model, train_losses, validation_losses, epochs_run=train_model(model,optimizer,criterion,num_epochs,train_loader=train_loader,validation_loader=validation_loader,validate=True, early_stopping=early_stopping, patience=3)

x=np.arange(epochs_run)
plt.plot(x,train_losses,label='Training loss')
plt.plot(x,validation_losses,label='Validation loss')
plt.title('Training and validation loss per epoch for chromagram',fontsize=12)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# testing
test_dataset = SpectrogramDataset('/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/', class_mapping=CLASS_MAPPING,train=False,spect_type='chromagram')
batch_train = 32
evaluate(model, test_dataset ,batch_train)

"""**Beat-synced chromagrams:**"""

#dataset split
batch_size = 32
val_size = 0.15
chromas = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/',class_mapping=CLASS_MAPPING,train=True,spect_type='chromagram')
train_loader, validation_loader = torch_train_val_split(chromas, batch_size ,batch_size, val_size)

#model parameters
rnn_dim = 64
input_dim = 12  # length of mel spectogram
output_dim = 10  # number of classes
num_layers = 2
num_epochs = 60
learning_rate = 1e-4
bidirectional = True 
dropout = 0.4
weight_decay = 1e-4
early_stopping = True

model = BasicLSTM(input_dim, rnn_dim, output_dim, num_layers, dropout=dropout)                      # initialize model
# model.to(device)
criterion = nn.CrossEntropyLoss()                                                                   # loss function
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)       # optimizer with L2 normalizaton

model, train_losses, validation_losses, epochs_run=train_model(model,optimizer,criterion,num_epochs,train_loader=train_loader,validation_loader=validation_loader,validate=True, early_stopping=early_stopping, patience=3)

x=np.arange(epochs_run)
plt.plot(x,train_losses,label='Training loss')
plt.plot(x,validation_losses,label='Validation loss')
plt.title('Training and validation loss per epoch for beat-synced chromagram',fontsize=12)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# testing
test_dataset = SpectrogramDataset('/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/', class_mapping=CLASS_MAPPING,train=False,spect_type='chromagram')
batch_train = 32
evaluate(model, test_dataset ,batch_train)

"""ζ)

**Απλά, concatenated:**
"""

#dataset split
batch_size = 32
val_size = 0.15
spects = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/',class_mapping=CLASS_MAPPING,train=True,spect_type='spectrogram')
train_loader, validation_loader = torch_train_val_split(spects, batch_size ,batch_size, val_size)

#model parameters
rnn_dim = 64
input_dim = 140  # 128+12 size
output_dim = 10  # number of classes
num_layers = 2
num_epochs = 60
learning_rate = 1e-4
bidirectional = True 
dropout = 0.4
weight_decay = 1e-4
early_stopping = True

model = BasicLSTM(input_dim, rnn_dim, output_dim, num_layers, dropout=dropout)                      # initialize model
# model.to(device)
criterion = nn.CrossEntropyLoss()                                                                   # loss function
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)       # optimizer with L2 normalizaton

model, train_losses, validation_losses, epochs_run=train_model(model,optimizer,criterion,num_epochs,train_loader,validation_loader=validation_loader,validate=True, early_stopping=early_stopping,patience=3)

x=np.arange(epochs_run)
plt.plot(x,train_losses,label='Training loss')
plt.plot(x,validation_losses,label='Validation loss')
plt.title('Training and validation loss per epoch for concatenated spectrograms and chromagrams',fontsize=12)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# testing
test_dataset = SpectrogramDataset('/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/', class_mapping=CLASS_MAPPING,train=False)
batch_train = 32
evaluate(model, test_dataset ,batch_train)

"""**Beat-synced concatenated**"""

#dataset split
batch_size = 32
val_size = 0.15
spects = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/',class_mapping=CLASS_MAPPING,train=True,spect_type='spectrogram')
train_loader, validation_loader = torch_train_val_split(spects, batch_size ,batch_size, val_size)

#model parameters
rnn_dim = 64
input_dim = 140  # 128+12 size
output_dim = 10  # number of classes
num_layers = 2
num_epochs = 60
learning_rate = 1e-4
bidirectional = True 
dropout = 0.4
weight_decay = 1e-4
early_stopping = True

model = BasicLSTM(input_dim, rnn_dim, output_dim, num_layers, dropout=dropout)                      # initialize model
# model.to(device)
criterion = nn.CrossEntropyLoss()                                                                   # loss function
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)       # optimizer with L2 normalizaton

model, train_losses, validation_losses, epochs_run=train_model(model,optimizer,criterion,num_epochs,train_loader,validation_loader=validation_loader,validate=True, early_stopping=early_stopping,patience=3)

x=np.arange(epochs_run)
plt.plot(x,train_losses,label='Training loss')
plt.plot(x,validation_losses,label='Validation loss')
plt.title('Training and validation loss per epoch for beat-synced concatenated spectrograms and chromagrams',fontsize=12)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# testing
test_dataset = SpectrogramDataset('/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/', class_mapping=CLASS_MAPPING,train=False)
batch_train = 32
evaluate(model, test_dataset ,batch_train)